{
  "name": "MDN",
  "tagline": "LSTM + MDN for basketball trajectories",
  "body": "#Mixture Density Network\r\n\r\nThis post implements a LSTM for sequence labelling. Inspired after Graves' handwriting work, we next implement such LSTM with MDN\r\nto model and generate new sequences.\r\n\r\nFor this post, I worked together with Rajiv Shah (link). Rajiv and I met on Github discussing LSTM's. How would LSTM's do on basketball\r\ntrajectories, was out topic of discussion. LSTM's are popular from NLP, where they map sequences of word vectors onto other\r\nsequencs of word vectors, or map onto a single label. Recently, LSTM's were also used in speech to map sequences of MFCC onto labels\r\nor video frams onto labels. The question we pondered was, how would the LSTM map sequences of coordinates onto labels. Coordinates, in\r\nour case, are the X,Y,Z and time coordinate of three-points shots. So more specifically \r\n__Can the LSTM map sequences of coordinates onto a label, predicting a succesful three pointer?__\r\n\r\n\r\nThe answer is yes. This post explains how we did it.\r\n\r\nFirst we discuss the LSTM, the experiments involved and the results. Second, we take Graves' handwriting work to a new level\r\nand implement it for our basketbal trajectories. We show that a MDN both models a trajectory well and that we can sample from\r\nthe consequetive distributions.\r\n\r\n#Model\r\nLSTM's map sequences onto other sequences. Hochreiter and Schmidhuber introduced them first in their paper. Later variants\r\nadd the forget gate and peepholes. \r\nA typical set of equations goes like this.\r\n\r\nThe input vector, x, is four-dimensional in our case. The hidden state, h, get propagated between time steps. This hidden state maps\r\nto an output distribution. The softmax squashes the real valued numbers to a probability distribution. This we can train via cross-entropy error.\r\n\r\n#Technical details\r\nLSTM's in Tensorflow come in two flavours. Some implementations treat the sequence, x, as a list. This list feeds into the seq2seq.rnn_decoder().\r\nThis implementation, however, passes the sequences, x, as a 3D Tensor. All input tensors are shaped [batch_size, num_coordinates, sequence_length]\r\n\r\n#Data\r\nThe basketbal trajectories originate from the SportVU data. SportVU systems track the coordinates of all 10 players and the ball, during the NBA games.\r\nFirst, we extract only three pointers from this dataset. For this step, all trajectories where the ball is higher than 8 feet qualify as three-pointer.\r\nThe dataloader() improves this extraction process, which we named __munging__. The munging function extracts an interesting dataset from the large dataset.\r\nFor example, we experimented with three pointers that are at least 11 feet and higher, stopped tracking at 4 feet from the basket and were 26 time-steps long. \r\nThat works with the following lines of code\r\n`\r\ndl.munge_data(11,26,4)\r\n`\r\n\r\n#Experiments and results\r\n\r\n-have to write something here-\r\n\r\n#Mixture Density Network\r\nDuring the project, we wondered if the LSTM really learned from the trajectory. How could we ascertain that the LSTM understood the trajectory, rather than using only\r\nthe final two time steps. That got us to Graves' handwriting work. Graves' models strokes of handwriting with a Mixture Density Network (MDN). At every coordinate, the LSTM\r\ngenerates a distributution for the offset to the next coorinate. At one timestep, you;re at coordinate (1,1), next at (2,2). Now __probably__ the next coordinate is (3,3). \r\nHowever, it could also be (3.1,3) or (2.9,2.8). How would we discern between those cases?\r\n\r\nWe parametrize a __distribution__ over the paper. This distribution represents how likely the next stroke will be at that coordinate. An example is this figure:\r\n![example MDN](https://github.com/RobRomijnders/MDN/blob/master/image/blog_example_MDN.png?raw=true)\r\nThis is a downward part of the trajectory. The ball *very probably* will move 0.4feet forward and 0.2feet downward. However, distribution also models the uncertainty other \r\noffsets. \r\n\r\n##Formalisms of the MDN\r\nWe approximate this distribution with a mixture of Gaussian distributuions. Gaussians are defined by their mean and covariance matrix. This makes them suitable for the task.\r\nEvery timestep, the LSTM outputs parameters that define this Gaussian. Every Gaussian requires seven parameters\r\n  * mean and variance in x\r\n  * mean and variance in y\r\n  * mean and variance in z\r\n  * covariance in xy plane\r\nSay you model your offsets with __K__ mixtures, you need __7K__ paramaters.\r\n\r\n##How do you train an MDN?\r\nThe MDN defines a distribution over coordinates for the offset. The distribution explains or models our data. Hence, the best MDN has the highest likelihood under our data. To maximize the likelihood function is also to minimize the log-likelihood function. Hence, these lines in the code summarize the training.\r\n```python\r\nloss = -tf.log(pd)  #pd is the probability density for the predicted offset\r\ncost = tf.reduce_mean(loss_seq)\r\n...\r\ntrain_step = optimizer.minimize(cost)  \r\n```\r\n\r\n##Experiments and results\r\nThis section contains many visualizations. The MDN parametrizes a distribution over the three-dimensional space. Therefore, the visualizations marginalize this distribution\r\nto obtain a plot in XY plane, XZ plane and YZ plane. \r\nThe following figure shows an example\r\n![Example MDN 1](https://github.com/RobRomijnders/MDN/blob/master/image/MDN_plots_works1.png?raw=true)\r\n  * Left upper plot: This plot shows the trajectory. The blue dot indicates which time step is being visualized\r\n  * Right upper plot: The trajectory goes in negative x direction and positive y direction. Indeed, the probability for this direction is high\r\n  * Left lower plot: The trajectory very probably goes downward in heigh (z coordinate) and forward (negative x coordinate)\r\n  * Right lower plot: The trajectory goes downward in height and in positive y direction\r\nAnother example of a trajectory in the upward part\r\n![Example MDN 2](https://github.com/RobRomijnders/MDN/blob/master/image/MDN_plots_works4_upwards.png?raw=true)\r\n\r\n\r\n#Sampling and biased sampling\r\n##Sampling\r\nNow a natural question to ask is\r\n__Can we sample new trajectories from the MDN?__\r\nThat answer is also __yes__.\r\n\r\nEvery time-step has a distribution for the offset to the next time-step. In the previous section we visualized this to learn about the trajectory. Another option\r\nis to sample from this distribution. If done for consequetive time steps, we can *generate* the full trajectory.\r\n\r\nTwo examples of these sampled trajectories are shown below\r\n![Example sampling 1](https://github.com/RobRomijnders/MDN/blob/master/image/generate_sequences_4_bias-0.png?raw=true)\r\n![Example sampling 2](https://github.com/RobRomijnders/MDN/blob/master/image/generate_sequences_2.png?raw=true)\r\n\r\n\r\n## Biased sampling\r\nOne problem with this sampling method is that errors add up. The LSTM bases its predictions on past time-steps. Therefore, the LSTM bases on the previous\r\ndraw from the dsitribution. That way, unfortunate draws propagate their error. \r\n\r\nA simple heuristic can improve this results. The sampling can be biased toward more probable predictions. In the first image, probable offsets in the z-plane\r\nrange from -0.1 to -0.6 feet. An unfortunate draw at, say, -0.6 feet will influence the remaining trajectory, like above. A *biased sample* is a sample more close\r\nto the mode of the distribution. For example, we not draw from the Gaussian between -0.1 and -0.6, but from a biased distribution between -0.3 and -0.4.\r\nThe sampled trajectories resemble more a true trajectory.\r\n\r\nTo illustrate this, the following figures show consequetively a sample with bias at 0.0, 1.0 and 2.0.\r\n![bias = 0](https://github.com/RobRomijnders/MDN/blob/master/image/generate_sequences_4_bias-0.png?raw=true)\r\n![bias = 1](https://github.com/RobRomijnders/MDN/blob/master/image/generate_sequences_4_bias-1.png?raw=true)\r\n![bias = 2](https://github.com/RobRomijnders/MDN/blob/master/image/generate_sequences_4_bias-2.png?raw=true)\r\nThe first five samples in each trajectory are the true coordinates. From time-step 5, the blue lines are the sampled trajectories. The red line is the trajectory that corresponds to the initial 5 coordinates and is shown for reference.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}